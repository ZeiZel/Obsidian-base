---
tags:
  - opengraph
  - og
  - meta
  - sitemap
  - robots
---

## SEO

SEO - search engine optimization - оптимизация поиска контента нашего сайта поисковиками

SEO влияет на ранжирование наших страниц

Ранжирование - это сортировка результатов по более релевантным для нас значениям

Все страницы на нашем сайте собираются в связную паутину: с главной на продукты, с продуктов, на продукт, с продукта обратно на главную. По этой патуине передвигаются веб-краулеры. 

Веб-краулеры передвигаются по страницам в рамках паутины движения по сайту и индексируют страницы. 

Индексация - это процесс прохождения по этим страницам и сбор информации для ранжирования

Влияет на ранжирование в поиске:
- количество страниц
- индекс цитируемости
- популярность
- глубина отказов (если пользователь выходит со страницы через 20 секунд, то он с чем-то сталкивается)
- уникальность
- скорость
- контент
- удобство
- доступность
	- скринридеры
	- реагирование на клавиатуру
	- семантика
	- роли
	- ARIA-теги
- география
- uptime (время доступности сервиса)
- поддержка мобилок (почти половина пользователей сидит в интернете с телефона)
- навигация (не нужно индексировать мусорные страницы)



---
## Мета

### Теги

#### заголовка

##### Статичные

Первым делом, обязательно, для определения основного контенгента пользователей, стоит указать язык, на котором должен шейриться сайт

```HTML
<html lang="ru">
```

Обязательно дальше идёт кодировка. Меняется она редко и только под специфические языки.

```HTML
<meta charset="UTF-8">
```

`vieport` определяет поведение браузера при масштабировании на разных девайсах. 
Например, админку на телефонах мы можем не давать приближать, а на маркетплейсах давать такую возможность, чтобы приближать картинки.  Так же тут мы определяем дефолтный масштаб для сайта. 

```HTML
<meta name="viewport" content="width=device-width, initial-scale=1.0">
```

##### Динамические

`title` - то, что отображается в строке браузера и выводится на главной поисковика. Тут должно быть максимум ключевых слов. 

```HTML
<title>Покупай и не грусти | Продаём книги</title>
```

![](../_png/Pasted%20image%2020251004114938.png)

`meta:description` - это описание, которое так же должно содержать максимум ключевых слов

```HTML
<meta name="description" content="Тут должно так же быть максимум ключевых слов...">
```

`meta:keywords` - отдельная секция с ключевыми словами через запятую

```HTML
<meta name="keywords" content="JS, JavaScript, TypeScript, SEO">
```

#### Семантика

Очень важной частью является семантика самой страницы. Если нам важно ранжирование страницы, то верстать всё в рамках только `div` будет нельзя. 

Нам для каждого своего элемента нужно обязательно будет:
- использовать свой семантический тег
- указывать роли
- обрабатывать действия

Тем более, правильные семантические теги дефолтно отрабатывают браузером правильно действия пользователя (клик по кнопке и так далее)

```HTML
<body>
    <header>
        <nav>
            <ul>
                <li>s</li>
                <li></li>
                <li></li>
                <li></li>
            </ul>
        </nav>
    </header>
    <aside>
        <a href="http://ya.ru" target="_blank" rel="noopener noreferrer">Я внешняя ссылка</a>
        <a href="/pupupu.html"></a>
    </aside>
    <section>
        <h1>Единственный заголовок</h1>
    </section>
    <footer>
        <div>
            <p>тексты</p>
        </div>
    </footer>
</body>
```



---
## Open Graph

Open Graph - это протокол ссылок, который позволяет делиться дополнительной информацией в соцсетях. 
Они подтягивают изображения и мета-описание, когда делишься ссылкой.

![](../_png/Pasted%20image%2020251004120530.png)

- `og:type` — определяет тип контента. Это помогает соцсетям понять, как правильно оформить блок при репосте.
	- `article` (статья)
	- `website` (общая страница сайта)
	- `video` и другие
- `og:url` — канонический (основной) URL страницы. Помогает соцсетям и мессенджерам корректно агрегировать статистику, показывать нужный адрес при клике по карточке
- `og:title` — заголовок, который будет показан в карточке при публикации ссылки. Обычно дублирует title или h1, но может быть короче и информативней
- `og:description` — краткое описание страницы или статьи. Отображается в карточке под заголовком. Важно писать ёмко и привлекательно, чтобы увеличить кликабельность
- `og:image` — ссылка на изображение, которое соцсеть или мессенджер подставит в превью карточки. Рекомендуется использовать картинки подходящего размера и без водяных знаков. Картинка влияет на привлекательность карточки
- `og:site_name` — дополнительный тег, обозначающий имя сайта или проекта. Показывается в некоторых соцсетях, объясняет, откуда эта статья или страница
- `og:locale` — язык страницы по формату ISO (например, ru_RU, en_US). Помогает определить локализацию контента. Используется не всегда, но улучшает предпросмотр для пользователей из нужного региона

```HTML
<head>
  <title>Пример страницы с OG</title>
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://mysite.com/post/123">
  <meta property="og:title" content="10 лучших практик фронтенд оптимизации">
  <meta property="og:description" content="Ваш гид по эффективному ускорению сайтов на практике." />
  <meta property="og:image" content="https://mysite.com/images/og-optimize.png">
  <meta property="og:site_name" content="Frontend Blog">
  <meta property="og:locale" content="ru_RU">
</head>
```



---
## Валидация HTML

Валидировать разметку можно с помощью разных ресурсов, например [validatorW3](https://validator.w3.org)

![](../_png/Pasted%20image%2020251004122716.png)



---
## Ссылки

### ЧПУ

ЧПУ - человекопонятные ссылки - ссылки, содержание которых будет понятно обычному живому человеку

Например: 
- `http :// cars.qq / auto / 123 / model / 4234` - это пример плохой ссылки: 
	- из контекста понятно только то, что она про машины, но дальше идут только цифры. 
- `httpS :// cars.qq / auto / bmw / model / m5` - это пример хорошей ссылки: 
	- защищена ssl-сертификатом (только такие выводятся в поиск)
	- в контексте указаны понятные наименования (выше конверсии)

### Canonical links

Каноничные ссылки - это тег, который указывает на оригинальную страницу

Часто бывает такая ситуация, когда несколько ссылок ведут на одну страницу. Разные пользовательские пути приводят по разным ссылкам на одну и ту же страницу. Из-за этого у нас появляются дубликаты страниц. 
Чтобы поисковой робот не воспринимал страницы как дубликаты, нужно указывать каноническую ссылку, которая очищена от фильтров и других путей.

```HTML
<!-- мы сейчас находимся на https://mysite.orig.com/products/books?filters=... -->
<link rel="canonical" href="https://mysite.orig.com/product/book/carl-marks/capital">
```

> Дубликаты тратят краулинговый бюджет! 



---
## Robots

Поисковые роботы - web crawlers, боты, пауки — это программы поисковых систем (Googlebot или YandexBot), которые автоматически переходят по страницам, анализируют их содержимое и добавляют в индекс. 

Основная их задача — находить новые и обновлённые страницы для отображения в поисковой выдаче.

Бот:

- Переходит по ссылкам и картам сайта (sitemap.xml, внутренние и внешние ссылки)
- Загружает HTML и другие ресурсы
- Запрашивает вложенные файлы (CSS, JS, изображения)
- Проверяет, не запрещено ли ему что-либо robots.txt или мета-тегами

### Теги

Задать значения для индексирования каждой страницы в отдельности мы можем через метатеги страницы со значениями:
- `index` / `noindex` - включение / отключение индексации
- `follow` / `nofollow` - контролирует отслеживание изменения страницы
- `all` - включение всего отслеживания

```HTML
<head>
  <meta name="robots" content="noindex, nofollow" />
  <meta name="googlebot" content="index, follow" />
  <meta name="yandex" content="noindex, nofollow" />
</head>
```

### Robots.txt

**robots.txt** — это текстовый файл, размещённый в корне сайта `https://mysite.com/robots.txt`, который указывает поисковым ботам, что можно и нельзя сканировать на сайте. 

С помощью него можно:

- Открыть или закрыть разделы сайта для индексации
- Контролировать нагрузку на сервер
- Защитить приватные или временные разделы от индексации

Файл состоит из директив:
- `User-agent:` — для кого применяется правило (например, для всех, для конкретного бота)
- `Disallow:` — запрещённый путь (URL путь или папка)
- `Allow:` — явно разрешённый путь (чаще для конкретных файлов внутри запрещённой папки)
- Дополнительно: `Sitemap:`, `Host:` (Яндекс)

```
# правила для всех
User-agent: *
Disallow: /admin/
Disallow: /private/
Allow: /private/open-info.html
Disallow: /tmp/

# Разрешаем всё для Googlebot Images
User-agent: Googlebot-Image
Disallow:

# Указание карты сайта для всех
Sitemap: https://mysite.com/sitemap.xml
```

Файл максимум до 500 кб

---
## Sitemap

Sitemap (карта сайта) — это файл, который содержит полный список важных страниц сайта. 

Он помогает поисковикам быстрее и эффективнее находить и индексировать страницы, особенно если сайт большой, с глубокой структурой или с динамически генерируемыми страницами.

Sitemap: 
- ускоряет обход сайта
- указывает поисковикам
	- какие страницы есть
	- когда они обновились
	- какие из страниц приоритетнее для индексации

Формировать файл нужно из канонических ссылок

`/sitemap.xml`
```XML
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>https://mysite.com/</loc>
    <lastmod>2025-10-01T12:00:00+03:00</lastmod>
    <changefreq>daily</changefreq>
    <priority>1.0</priority>
  </url>
  <url>
    <loc>https://mysite.com/about</loc>
    <lastmod>2025-09-28T09:30:00+03:00</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <url>
    <loc>https://mysite.com/blog/post-123</loc>
    <lastmod>2025-10-03T15:45:00+03:00</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.9</priority>
  </url>
  <!-- Добавляйте столько <url>, сколько страниц хотите указывать -->
</urlset>
```

Файл максимум до 50 мб, но в Sitemap можно указывать ссылки на другие карты сайта и реализовать сразу несколько сайтмапов, если ссылок крайне много

Этот файл нужно будет так же указать в файле `robots.txt`

`/indexsitemap.xml`
```XML
<?xml version="1.0" encoding="UTF-8"?>
<sitemapindex xmlns="https://www.sitemaps.org/schemas/sitemap/0.9">
  <sitemap>
    <loc>https://mysite.com/sitemap-main.xml</loc>
    <lastmod>2025-10-01T08:30:00+03:00</lastmod>
  </sitemap>
  <sitemap>
    <loc>https://mysite.com/sitemap-blog.xml</loc>
    <lastmod>2025-09-29T12:00:00+03:00</lastmod>
  </sitemap>
  <sitemap>
    <loc>https://mysite.com/sitemap-shop.xml</loc>
    <lastmod>2025-10-02T17:45:00+03:00</lastmod>
  </sitemap>
</sitemapindex>
```



---
## Мусорные страницы


### Краулинговый бюджет





## Метрики

Web Vitals

Lighthouse












## Оптимизация





## Микроразметка










## Uptime










## SSR / SPA











