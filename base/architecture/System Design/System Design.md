---
tags:
  - systemdesign
  - db
---



---

## Основные термины

### Архитектуры ИС

#### Файл-сервер

Файл-сервер только извлекает данные из файла или базы данных и передаёт их клиенту для дальнейшей обработки.

![](../../_png/Pasted%20image%2020260207150357.png)

Её минусы: 

- клиент должен знать, что делать с данными
- не безопасно отдавать клиенту все данные


>[!warning] Это устаревшая архитектура

Однако можно найти подобие таким системам в: системах хранения данных (google drive, яндекс облако, nexcloud)

#### Клиент-сервер

Клиент-сервер извлекает данные из файла или БД, обрабатывает и затем передаёт результат клиенту

![](../../_png/Pasted%20image%2020260207150417.png)

Плюсы: 

- клиент выполняет заранее предопределённые действия
- безопасно

#### Peer-2-Peer

Все одноранговые узлы выполняют одинаковые функции - нет централизованного сервера

![](../../_png/Pasted%20image%2020260207150431.png)

Подходит для блокчейна и торрентов

### Основные критерии ИС

#### Надёжность

Система должна продолжать работать корректно даже при неблагоприятных обстоятельствах

| Уровень доступности                 | Процент uptime | Простой в год | Простой в месяц | Простой в день |
| ----------------------------------- | -------------- | ------------- | --------------- | -------------- |
| 1 Nine - Conventional Server        | 90%            | 36.5 дней     | ~73 часа        | 2.4 часа       |
| 2 Nines - Public Cloud Service      | 99%            | 3.65 дней     | ~7.3 часа       | 14 минут       |
| 3 Nines - High-Availability Cluster | 99.9%          | 8.76 часов    | ~43 минуты      | 86 секунд      |
| 4 Nines - Virtual Fault Tolerance   | 99.99%         | 52.6 минут    | ~4 минуты       | 8.6 секунд     |
| 5 Nines - Continuous Availability   | 99.999%        | 5.26 минут    | ~25 секунд      | 0.86 секунд    |
| 6 Nines - The Stratus Zone          | 99.9999%       | 31.6 секунд   |                 |                |

 Термины доступности: 
 
 - Uptime - сервис обрабатывает запросы (сервис работает **надёжно**)
 - Downtime - сервис возвращает 500 или любую другую ошибку (но не лежит) (сервис **доступен**)

Все показатели, какой функционал должен работать всегда, а какой лежать - нужно заранее обговаривать с заказчиком. 

Метрики доступности: 

- SLA (Service Level Agreement) - соглашение, которое вы заключаете со своими клиентами
- SLO (Service Level Objectives) - цели, которые команда должна решить, чтобы выполнить соглашение
- SLI (Service Level Indicators) - показатели системы (факт)

Команда должна обеспечить определённый SLO (цели), но при его недостижении, мы понесём потери в виде SLA (соглашение), а SLI - это наш факт

В жизни это выглядит так: Google обязуется возместить 50% стоимости подписки, если месячный Uptime ниже 95%

![](../../_png/Pasted%20image%2020260202211517.png)

#### Масштабируемость

Должны быть предусмотрены разумные способы решения, возникающих при росте системы, проблем 

- Вертикальное масштабирование - расширение ресурсов ноды
	- стоимость увеличения ресурсов растёт не линейно, а относительно увеличения мощности
	- возможен downtime (не всё поддерживает хотсвап ОЗУ и ЦПУ)
	- невозможно бесконечно масштабироваться
	  
	  ![](../../_png/Pasted%20image%2020260207150511.png)
	  
- Горизонтальное масштабирование - увеличение количества нод
	- распределение нагрузки на несколько серверов
	  
	  ![](../../_png/Pasted%20image%2020260207150524.png)

Ситуации: 

- когда мы стартап и нам нужно быстро проверять гипотезы, то монолит - это самый простой и быстрый вариант, где вертикально отмасштабироваться будет быстрее и проще
- сильно дешевле взять много серверов с минимально необходимым количеством ресурсов для поднятия одного или нескольких сервисов, вместо меньшего количества более мощных серверов

#### Stateless и Statefull

Глобально у нас есть два типа сервисов: 

- Stateless - не хранят никаких данных в памяти сервера
	- легко масштабировать
- Statefull - хранят данные для работы
	- тяжело масштабировать
		- нужно мигрировать данные с одного сервиса на другой
		- правильно определять балансировать запросы, чтобы они доходили до конкретного сервиса

#### Производительность

- Latency Time - это время между запросом и началом обработки этого запроса конечным сервисом
	- Эта метрика может считаться на разное количество рангов общения (клиент-сервер, клиент-сервер-бд, сервер-бд и тд)
	- Задержки могут быть, когда: 
		- запрос встаёт в TCP очереди
		- ядро сняло поток с выполнения
		- запрос ожидает другого ивента
		- запрос просто в очереди RMQ
- Response Time - время обработки запроса целиком (все промежутки от отправки запроса и ответом клиенту)

![](../../_png/Pasted%20image%2020260207150545.png)

Latency железа на чтение 1 МБ: 

- RAM - 250 000 нс
- SSD - 1 мс
- HDD - 20 мс 

Класс систем Low-latency приложений - это приложения, которые требуют оптимизации под низкую задержку прямо с самого начала разработки. MVP подход апгрейда кода до оптимизированного стандарта тут не подойдёт.  

Throughtput - это пропускная способность ресурса на определённую единицу времени

Пример: в секунду клиент отправил 200 запросов, сервер передал в БД 120 запросов, база вернула ответ на 100 запросов, сервер обработал и вернул 95 ответов. 95 запросов обработает наш сервис в секунду.  

![](../../_png/Pasted%20image%2020260207150559.png)

Throughput железа: 

- DDR3 - 17 000 мб/с
- SSD - 600-700 мб/с
- HDD - 200-300 мб/с

High-throughput приложения - это приложения, которые заточены под максимально возможноую пропускную способность. В таких часто пренебрегают latency. 
В таких приложениях очень важны очереди и группировки сообщений, чтобы была возможность обрабатывать их группой и обрабатывать максимальное количество запросов. Тут не получится сохранить максимум latency, так как там очередь - это дополнительная задержка запроса.  

Пример: разрабатываем приложение с максимальным throughput, который мы можем выжать в рамках latency = 1 секунде на весь путь. 

#### Удобство сопровождения

Необходимо обеспечить возможность эффективной работы с системой множеству различных людей. 

Метрики: 

- Observability (мониторинг)
- Улучшение процессов
- Дополнительный инструментарий

#### Безопасность

- передача данных в открытом виде - полностью работаем с данными в открытом виде
- транспортное шифрование - шифруем данные с клиента и сохраняем их зашифрованными
- сквозное шифрование - храним в открытом виде, а при передаче шифруем (с клиента на сервер и обратно)

### Основные свойства ИС

#### Data / read intensive

1. Data-intensive

Это приложения с преимущественной IO-bound нагрузкой (максимум на запись и чтение)

- Нужно сохранять большие данные
- Нужно запоминать результаты ресурсоёмких операций
- Нужно предоставлять пользователям возможность искать или фильтровать данные

2. Compute-intensive

- Нужно делать много вычислительных операций
- Нужно перемалывать большие объёмы данных

#### Read / write ratio

От класса системы будет сильно зависеть его основная цель: 

- соцсети мало Пишут постов, но много читают
- логи много пишут, но мало читают

![](../../_png/Pasted%20image%2020260207150717.png)

### Архитектура бэкенда

#### Монолиты

Монолит - это единое приложение со всеми сервисами внутри себя

Они хорошо подходят для: 

- стартапов
- low-latency систем 

#### Микросервисы

[Микросервисная архитектура](../../backend/Microservices/Микросервисы.md) - это подход разработки бэкэнда, когда мы приложение описываем различными сервисами, которые общаются друг с другом

Особенности:

- сервисы делятся по зонам ответственности
- каждый МС самодомтаточен и идеален для горизонтального масштабирования
- позволяют использовать разные технологии для разных задач
- позволяют распределять кодовую базу

Плюсы: 

- независимые релизы и разработка
- независимая масштабируемость
- независимая деградация
- возможность попробовать новые технологии

Минусы: 

- очень большой стек (экспертиза размазывается)
- сетевой вызов отвалится вероятнее, чем внутренний
- распределённость и транзакционность
- удалённые вызовы дороже локального исполнения
- требуется понимание всего контекста запроса
- сложно тестировать такую систему

### Балансировка нагрузки и проксирование

Следующая проблема - это распределение всех поступающих запросов на разные сервисы

#### Балансировка
##### Клиентская балансировка

Клиент сам отправляет запросы на разные инстансы

![](../../_png/Pasted%20image%2020260207150743.png)

##### Серверная балансировка

Следующим вариантом будет балансировка запросов и их распределение через отдельный Load Balancer (LB)

![](../../_png/Pasted%20image%2020260207150752.png)

Самый простой вариант - рандомная рассылка запросов в разные сервисы

![](../../_png/Pasted%20image%2020260207150821.png)

- Round Robin
	- RR - распределение запросов по нескольким инстансам одного сервиса (запросы просто раскидываются поочерёдно друг другу)
	- Weighted RR - распределение запросов на разные инстансы, которые имеют свой вес. Этот подход нужен, когда разные сервера могут перемалывать разное количество задач. Выше вес - больше запросов может в себя принять.
	- Sticky RR - когда наш сервер хранит кэш-данные по пользователю, нам нужно присвоить запросам этого пользователя определённый hash_id, по которому мы его определим и будем ссылать его запросы на нужный инстанс 
- Least Connections - распределение нагрузки по оставшемуся количеству коннектеров
- Response Time - чем меньше время отклика от сервера, тем больше туда запросов будет отправлять LB
- Least Time
- Bandwidth
- Power of two choices - случайным образом выбираем два бэкэнда из списка по целевым метрикам: least connections, sessions, bandwidth и так далее

![](../../_png/Pasted%20image%2020260207120914.png)

##### OSI балансировка

- L3-4 - Network Load Balancer - сетевой (резолв ip) / транспортный уровни (резолв портов) - определяет количество открытых connections от клиента и предоставляет такое же количество до целевого сервера
- L7 - Application Load Balancer - смотрит на количество прилетевших запросов и сам может определить, сколько коннекций и до какого сервера ему открыть

![](../../_png/Pasted%20image%2020260207150909.png)

##### Мультибалансировщики

###### DNS

Если нам потребуется сразу несколько балансировщиков для того, чтобы избежать единственной точки отказа в виде LB и распределить нагрузку по нескольким, то мы можем попробовать скрыть несколько сервисов балансировщиков за одним DNS именем

```bash
$ nslookup ya.ru

Server:		1.1.1.1
Address:	1.1.1.1#53

Non-authoritative answer:
Name:	ya.ru
Address: 77.88.55.242
Name:	ya.ru
Address: 77.88.44.242
Name:	ya.ru
Address: 5.255.255.242
```

В таком случае балансировка балансировщиков происходит простым образом: DNS всегда отдаёт в рандомном порядке IP адреса балансировщика, что размазывает нагрузку по ним всем. 

![](../../_png/Pasted%20image%2020260207150925.png)

###### GeoDNS

Так же для того, чтобы ускорить ответ клиенту, мы можем определять геопозицию пользователя по IP через MaxMind и предоставлять ему сервера, которые находятся в его регионе.

![](../../_png/Pasted%20image%2020260207150939.png)

#### Проксирование

Проксирование позволяет нам организовать одну единственную точку входа в приложение, в рамках которой можно организовать:

- защиту от взлома
- кэширование данных
- ограничение трафика
- обход ограничений доступа
- анонимность пользователей
- сжатие и модификацию данных

![](../../_png/Pasted%20image%2020260207150956.png)

##### Forward-proxy

Это когда приложение знает, что оно пойдёт через Proxy

Пример: мы, как пользователи, ставим прокси, чтобы получить доступ к ресурсу

![](../../_png/Pasted%20image%2020260207151005.png)

##### Reverse-proxy

Приложение не знает, что есть определённое Proxy, через которое оно ходит

![](../../_png/Pasted%20image%2020260207151015.png)

### Кэширование

Основные предназначения: 

- Сокращение Response Time сервисов
- Снижение лишней нагрузки на сторонние сервисы
- Переиспользование ранее полученных или вычисленных данных
- Стабилизация работы при кратковременных отказах систем

Термины:

- Cache miss - промах кэша, запрошенный ключ не был найден в кэше
- Cache hit - попадание в кэш, запрошенный ключ найден в кэше
- Hit ratio - процент попаданий запросов в кэш, характеризует эффективность кэширования
- Горячий ключ - ключ, на который приходится большая часть запросов
- Прогрев кэша - процесс наполнения кэша данными
- Инвалидация - удаление кэшированных данных

Какие данные кэшировать:

- Меняются часто (секунды) - кэшировать чаще всего бессмысленно, но иногда может пригодиться
- Меняются нечасто (минуты и часы) - чаще всего здесь нужно задаться вопросом "стоит ли это вообще кэшировать"
- Меняются редко (дни, недели, месяцы) - в данном случае можно спокойно кэшировать эти данные

Кэширование ошибок: 

- Кэшируем ошибки и тогда последующие запросы не будут обращаться к источнику информации
	- мы можем каждый раз не возвращать пользователям статус того, что нет определённого элемента по этому id из базы данных, а вернуть закэшированный отает
- Такой подход позволяет избежать *cache miss attack*

>[!info] По хорошему, нужно уметь держать нагрузку без кэша
> Задача кэша - ускорить ответ, но никак не держать нагрузку!

#### Эффективность

Эффективность кэша считается по следующей формуле: 

`AverageTime = DBAccessTime * CacheMissTime + CacheAccessTime`

Если: 

- DBAccessTime = 100ms
- CacheAccessTime = 20ms

То при CacheMissRate > 0.8, кэш будет вреден

#### Виды кэширования

##### Внутреннее

Использование кэша прямо внутри сервиса

Плюсы: 

- Высокая скорость
- Отсутствие сетевых запросов
- Нет расходов на Marshalling / Unmarshalling данных

Минусы: 

- сложности с горизонтальным масштабированием
- прогрев кэша

![](../../_png/Pasted%20image%2020260207151535.png)

##### Внешнее

Сервис ходит в определённый сервис, чтобы кэшировать или стягивать кэш из другого приложения

Плюсы: 

- Хранение большого объёма кэша
- Простое горизонтальное масштабирование
- После падения сервиса данные кэша не теряются
- Простой прогрев кэша и простая логика инвалидации

Минусы: 

- более низка скорость работы

![](../../_png/Pasted%20image%2020260207151605.png)

#### Способы взаимодействия с кэшем

##### Cache Aside

Эта стратегия подразумевает, что приложение координирует запросы в кэш и БЛ и само решает, куда и в какой момент нужно обращаться 

###### Read Aside

Чтение делится на несколько этапов:

1. Читаем кэш
2. Данных нет
3. Читаем базу
4. Получаем ответ
5. Пишем в кэш

Из минусов: медленное чтение

![](../../_png/Pasted%20image%2020260207151732.png)

###### Write Aside

Тут такой же флоу работы с данными: 

1. Пишем в базу
2. Получаем ответ
3. Сохраняем в кэш

Запись работает так же медленно

![](../../_png/Pasted%20image%2020260207151807.png)

##### Cache through

Эта стратегия подразумевает пропуск всех запросов от приложения через кэш. То есть приложение не знает про существование БД и сразу идёт за данными в кэш

Плюсы: 

- Приложение знает только про кэш и работает только с ним

Минусы: 

- достаточно сложная реализация (нужно заполнять данными из БД, писать воркеров, составлять процедуры для правильной работы с данными из кэша в БД)
- сложная инфраструктура

###### Read Through

Тут путь достаточно простой: 

1. Читаем из кэша
2. Кэш либо отдаёт данные, либо идёт в БД
3. После получения данных кэш-сервисом, отдаём их сервису

![](../../_png/Pasted%20image%2020260207151917.png)

###### Write Through

При записи мы так же пишем только в кэш и получаем ответ из этого же сервиса

![](../../_png/Pasted%20image%2020260207151931.png)

##### Cache Ahead

Опережающее кэширование. При таком подходе запросы на чтение всегда идут только в кэш, никогда не попадая в БД напрямую. 

Плюсы:

- сохраняем Latency на общении с БД

Минусы:

- нужна реализация периодической синхронизации

![](../../_png/Pasted%20image%2020260207152008.png)

#### Алгоритмы вытеснения данных

Возникает ситуация: у нас в кэше становится недостаточно места для добавления новых данных. Чтобы решить эту проблему, нам нужно определённым способом определить, какие данные лишние

![](../../_png/Pasted%20image%2020260207152205.png)

##### Random

Вытеснение любых данных

![](../../_png/Pasted%20image%2020260207152225.png)

##### FIFO

При добавлении новой записи, мы стираем самую старую

В кэш добавили 4 пользователей и самое первое вхождение заменяем на пользователя_5

![](../../_png/Pasted%20image%2020260207193255.png)

##### LIFO

Перетираем последние вошедшие данные

![](../../_png/Pasted%20image%2020260207193310.png)

##### LRU

Тот, кого не используют дольше всех - вылетает из кэша

Мы добавили пользователей 1, 2, 3, 4. Они в очереди идут последовательно друг за другом. Потом у нас запросили пользователя_1 и вызывали операцию по добавлению пользователя_5. Нам придётся выкинуть пользователя_2, так как обращение к нему было в истории операций самым старым.  

![](../../_png/Pasted%20image%2020260207193352.png)

##### MRU

Most Recently used

Последний использованный вылетает из кэша

Последней операцией мы получили пользователя_3, поэтому мы сотрём его и вставим на его место пятого юзера

![](../../_png/Pasted%20image%2020260207193403.png)

##### LFU

Last Frequently Used - реже всего использованный вылетает из кэша

![](../../_png/Pasted%20image%2020260207193618.png)

##### Алгоритм Белади (OPT)

Это теоретический алгоритм, так как во время его использования нужно чётко понимать, как часто мы обращаемся к элементам. 

Условно, если к данным мы обратимся через 3 минуты, то их мы можем заменить на те, к которым мы обратимся повторно через 7 секунд.

![](../../_png/Pasted%20image%2020260207193744.png)

##### Second Chance

В этом алгоритме используется классический FIFO, но добавляется дополнительный бит used, который сохраняет факт того, что данные использовались

Пример: 

1. У нас есть очередь из четырёх значений (максимум 4)
2. Мы прочитали данные пользователя_1 и поставили бит того, что эти данные мы читали недавно
3. Дальше запросили данные по пользователю_3 и ставим так же бит использованности
4. Потом мы устанавливаем новые данные и начинаем проходку по стиранию бита использования
5. Мы попали на пользователя_1 и убираем его бит в 0, так как он не использовался
6. Далее попали на пользователя_2 и так как у него нет бита, то вставляем данные в этот блок
7. Дальше проходиться нам не нужно и на пользователе_3 остаётся бит использованности 

Этот подход может дать сбой, так как если все данные будут иметь бит использованности, то произойдёт просто проходка по всем данным и ничего не произойдёт

![](../../_png/Pasted%20image%2020260207193756.png)

##### Clock

Этот алгоритм работает так же, как и Second Chance, но включает ещё одну сущность в виде указателя и зацикливает буффер. Такой подход не будет заставлять проходить всю очередь снова, а начнёт с последней точки выполнения.  

![](../../_png/Pasted%20image%2020260207193819.png)

##### 2Q

Этот алгоритм включает у нас сразу несколько очередей: FIFO x2 и LRU x1. Когда FIFO1 достигает максимума, то данные **вытесняются** в следующую очередь (FIFO2). Когда данные вытесняются из FIFO2, то они залетают в LRU.
Когда данные стираются и из LRU очереди, то они одновременно стираются и из первых двух очередей, если там находились. 

Этот подход нужен, когда на старте мы запускаемся и нужно прогреть сервис кэша нужными данными. 

![](../../_png/Pasted%20image%2020260207193828.png)

##### SLRU

Данный подход позволяет нам реализовать систему, в которой мы формируем несколько уровней кэширования: горячий (самый используемый), тёплый (часто используемый) и холодный (редкоиспользуемые данные, которые чаще всего вытесняются) кэши. 

Тут мы реализовали один LRU, но разделили данные по частотности. То есть совмещаем LRU с LFU. 

1. У нас изначально есть только Cold очередь
2. При обращении к данным из Cold, они попадают в Warm
3. И в конце при обращении к данным из Warm очереди, они попадают в Hot
4. При вытеснении из Cold, данные удаляются из всех очередей

![](../../_png/Pasted%20image%2020260207193836.png)

##### TLRU

Точно то же самое, что и LRU, но с добавлением TTL кэша, после достижения которого, значение удаляется из очереди

##### LRU-k

Удаляет страницу, K-й последний доступ к которой находится дальше всего в прошлом. 

Например, LRU-1 будет работать, как обычный LRU. LRU-2 будет удалять страницу в соответствии с их предпоследним доступом.

### API

[Способы взаимодействия систем](../../concepts/Client-server%20architecture.md)

#### CRUD

CRUD - это акроним базовых операций, которые используются для работы с данными: create, read, update, delete

#### REST

- Глагол - метод запроса
	- create - POST
	- read - GET
	- update - PUT/PATCH
	- delete - DELETE
- Существительное - URI запроса
- Содержимое - тело запроса и ответа (`json`, `binary`, `multipart/form-data`)
- Результат - код ответа

![](../../_png/Pasted%20image%2020260207205319.png)

>[!success] Отличный выбор для клиентского взаимодействия

#### SOAP

Более устаревший вариант, который хранит данные, метатеги, все коды ответа в теле запроса 

![](../../_png/Pasted%20image%2020260207205509.png)

>[!warning] не стоит пользоваться этой технологией

#### RPC

Класс технологий, который позволяет удалённо вызывать процедуры и функции в другом адресном пространстве. 

Например, вызывать функцию получения данных из одного сервиса в другом и получить результат выполнения так, будто мы вызывали функцию этого сервиса, а не другого.

##### gRPC

gRPC - это реализация от Google, которая позволяет разметить запрос и ответ через protobuf (слева) и далее мы просто в коде вызываем этот метод в Go как часть кода этого сервиса (справа) 

![](../../_png/Pasted%20image%2020260207154512.png)

##### Внутреннее устройство

Сам RPC передаёт все данные в виде байтов, что сильно сжимает сообщения и позволяет эффективнее пользоваться трафиком

![](../../_png/Pasted%20image%2020260207154523.png)

>[!success] Очень хорошо подходит для организации внутреннего взаимодействия в рамках микросервисной архитектуры с поддержанием контрактов через протобафы 

####  Under / Over fetching

У нас есть проблема: 

- Веб-приложение требует от АПИшки одних данных
- Мобильное приложение требует меньше данных, чем нужно вебу
- Десктопное запрашивает больше данных, чем нужно вебу

В итоге один сервис получает больше данных, чем ему нужно, а другой меньше и дозапрашивает данные другим запросом. Нет какой-то золотой середины по требуемым данным для разных сервисов.

##### GraphQL

GraphQL решает проблему фетчинга данных, так как теперь каждая платформа вольна запросить ровно те поля и в том формате, которые ей нужны для работы. 
То есть работа на фронте будет выглядеть подобно работе с базой данных, когда мы сами определяем нужный формат данных.

Так выглядит запрос данных:

![](../../_png/Pasted%20image%2020260207154643.png)

Так выглядит изменение данных:

![](../../_png/Pasted%20image%2020260207154651.png)

Так выглядит подписка на изменение событий:

![](../../_png/Pasted%20image%2020260207154701.png)

>[!success] Хорошо подходит для запросов, где важна кастомизация и оптимизация количества данных, передаваемых по сети

### Observability

Наблюдаемость системы - это важный фактор, который позволяет вовремя определить сбои и их возможное место появления. 

#### Мониторинг

Самый базовый инструмент, который нам нужен для того, чтобы вовремя отследить аномалии в работе приложения - это мониторинг. 

Например, в приложение мы добавляем код, который позволяет имплементировать мониторинг и его составные части. 

![](../../_png/Pasted%20image%2020260207154350.png)

Самый базовый инструмент для мониторинга - это Prometheus. Он является базой. 

![](../../_png/Pasted%20image%2020260207210638.png)

Внутри дэшборда мы можем увидеть любые параметры, которые грузят нашу систему

![](../../_png/Pasted%20image%2020260207154409.png)

Обычно, в дэшборд не смотрят 24/7, а настраивают алёрты на параметры, которые пробили пороговые значения. 

#### Основные метрики

- RPS (response per second), QPS (query per second), TPS (transactions per second - в рамках транзакции может быть несколько query)
- Response Time
- Errors Rate
- Traffic, CPU, RAM, HDD/SSD
- Uptime / Downtime
- Размеры очередей
- Количество процессов / потоков

#### Трейсинг

Нам нужен трейсинг запросов, когда в нашей системе много запросов и они ходят между микросервисами. 

Это удобно, когда нужно найти тот момент, где зафейлился запрос вместо логирования каждой машины и поиска упавшего места.

Jaeger или Zipkin

![](../../_png/Pasted%20image%2020260207154320.png)

И на диаграмме будет чётко видно, где стрельнула ошибка и что произошло не так, на каком моменте

![](../../_png/Pasted%20image%2020260208103855.png)

Так же эта структура позволяет построить граф зависимостей

![](../../_png/Pasted%20image%2020260208104032.png)

#### Логирование

Самый болезненный вариант - подключаться к машине по SSH и grep'ать логи с сервера

![](../../_png/Pasted%20image%2020260207153931.png)

Более красивый вариант - отправлять все логи на одну определённую машину и уже подключаться к ней, чтобы собрать нужные данные 

![](../../_png/Pasted%20image%2020260207153941.png)

Ещё более хороший вариант - поднять демона, который будет собирать логи со всех машин на наш отдельный сервис с логами

![](../../_png/Pasted%20image%2020260207153953.png)

И реализация логирования через классический стек: ELK или GrayLog - самый удобный вариант развития событий, когда нам достаточно в одном интерфейсе стянуть все логи

![](../../_png/Pasted%20image%2020260207154006.png)

#### Непрерывное профилирование

Когда мы по метрикам определили, что у нас какой-то сервер оффнулся ночью, то уже дальше в ход идут инструменты непрерывного профилирования, которые позволяют нам определить, что кушало максимум ресурсов в этом сервисе

Инструменты: 

- Parcq
- Pyroscope

Видим, что определённый метод загрузил систему на определённое количество времени и съел определённое количество ресурсов: 

![](../../_png/Pasted%20image%2020260207154105.png)

![](../../_png/Pasted%20image%2020260207154123.png)

Так же все ошибки мы можем собирать в Sentry вместо того, чтобы снимать дампы самостоятельно

![](../../_png/Pasted%20image%2020260207154246.png)

## Хранение данных

### Виды баз данных

#### Реляционные

Реляционные БД - это самый распространённый вариант, который решает 90% задач. Все остальные задачи так же можно решить с помощью них, но не так эффективно. 

Такой тип баз данных типизируемый. 

![](../../_png/Pasted%20image%2020260208114235.png)

#### Документоориентированные

Данный тип БД позволяет нам запихнуть без типизации документ. Зачастую, в виде JSON. 

Тут нет строгой типизации, поэтому объекты могут спокойно отличаться друг от друга (где-то будет поле `name`, а где-то нет). 

Очень полезно, когда у бизнеса нет чётких требований. Если требования постоянно меняются, то в реляционных придётся писать много миграций, а тут с этим будет проще.

![](../../_png/Pasted%20image%2020260208114316.png)

Как хороший кандидат для сохранения в NoSQL БД - резюме. Достаточно много документов, которые не требуют связей между друг другом. 

#### Поисковые движки

Это БД, которые являются надстройкой над NoSQL, которые позволяют эффективно искать документы. Они имеют больше параметров, их алгоритмы оптимизированы именно под быстрый поиск данных. 

- Elasticsearch
- Sphinx

Нпример, когда мы вводим "ИП", у нас ищутся не только строки с "ИП" внутри, но и "Индивидуальные Предприниматели", и "Бизнес", и "Малый Бизнес". Тут берётся более широкая выборка в системе и сравниваются поиски с синонимами, словарями и похожими данными. 

>[!warning] Однако в таких БД не стоит хранить данные - это антипаттерн!
> Лучшим вариантом будет поднять отдельную БД, в которой мы будем хранить данные и отдельно рядом поднять Elastic, который будет по этим данным проходиться и искать.

#### Графовые

![](../../_png/Pasted%20image%2020260208114408.png)

#### Key-value



![](../../_png/Pasted%20image%2020260208114442.png)



- Apache ZooKeper
- etcd (k8s)

#### Колончатые



![](../../_png/Pasted%20image%2020260208114608.png)

#### TimeSeries



![](../../_png/Pasted%20image%2020260208114628.png)

#### Blob Store



![](../../_png/Pasted%20image%2020260208114710.png)

### Выбор Базы данных

Параметры:

1. Транзакции
2. Формат данных
3. Навык работы с технологией команды
4. Характер обращения к данным
5. Сообщество и зрелость технологии
6. Частота изменений формата данных

Пример: 

1. Денежные средства пользователей
2. Количество просмотров под видео
3. Анкеты пользователей
4. Отношения между пользователями
5. Исходный код программ
6. Показатели температурных датчиков

Нужно сохранять и искать посты пользователей с использованием полнотекстового поиска, хранить аналитику и кэшировать популярные посты.

### Классы баз данных

#### OLAP vs OLTP

- Online Analytical Processing
- Online Transaction Processing

#### HTAP

- Hybrid Transactional / analytical processing

#### Persistent БД

БД, которые хранят свои данные на дисках.

#### In-memory БД

- Можно периодически записывать на диск копии состояния БД
- Можно записывать на диск копии журналов изменений, но не сами данные
- Можно проводить репликацию состояния оперативной памяти на другие машины

#### Embeded database



#### Single file database

### Индексы

- Ускоряют чтение
- Замедляют запись
- Используют дополнительную память

#### BTree

![](../../_png/Pasted%20image%2020260209203812.png)

#### Hash

![](../../_png/Pasted%20image%2020260209203826.png)

#### Bitmap

![](../../_png/Pasted%20image%2020260209203843.png)

#### Spatial

![](../../_png/Pasted%20image%2020260209203919.png)

#### Reversed

![](../../_png/Pasted%20image%2020260209203937.png)

#### Разряженный индекс

Каждый ключ ассоциируется с определённым указателем на блок в сортированном файле данных, а не с какой-то определённой записью.

#### Покрывающий индекс

Это некластеризованные индексы, которые разрешают один или несколько схожих результатов запроса напрямую, без доступа к базовой таблице и без уточняющих запросов.

#### Кластерные и некластерные

При наличии кластерного индекса строки таблицы упорядочены по значению ключа этого индекса. Если в таблице нет кластерного индекса, таблица называется кучей. Некластерный индекс, созданный для такой таблицы, содержит только указатели на записи таблицы.

### Транзакции

#### ACID

ACID - это стандарт того, какие гарантии должна давать база данных, чтобы поддерживать транзакции (но не указывает детали реализации).

Популярные БД появились на почве ACID.

##### Атомарность

Каждая транзакция базы данных является единым блоком, который использует подход "всё или ничего" к выполнению. Если какой-либо оператор теряет неудачу, то вся операция откатывается. 

![](../../_png/Pasted%20image%2020260209205344.png)

###### Rollback

![](../../_png/Pasted%20image%2020260209205414.png)

###### Commit

![](../../_png/Pasted%20image%2020260209205431.png)

##### Согласованность

Различные утверждения относительно данных должны всегда оставаться справедливыми

![](../../_png/Pasted%20image%2020260210202517.png)

###### Deferrable transactions


```SQL
CREATE TABLE husbands ( id int PRIMARY KEY, wife_id int NOT NULL

CREATE TABLE wives ( id int PRIMARY KEY, husband_id int NOT NULL

ALTER TABLE husbands ADD CONSTRAINT h_w_fk

FOREIGN KEY (wife_id) REFERENCES Wives;

ALTER TABLE wives ADD CONSTRAINT w_h_f

FOREIGN KEY (husband_id) REFERENCES husbands;
```

##### Изоляция транзакций

Каждая транзакция происходит до или после каждой другой транзакции, и представленние базы данных, которое транзакция видит в своём начале, изменяется только самой транзакцией до её завершения. Ни одна транзакция не должна видеть промежуточный продукт другой транзакции.  

###### Потерянное обновление


![](../../_png/Pasted%20image%2020260216200739.png)


###### Грязное чтение



![](../../_png/Pasted%20image%2020260216200815.png)


###### Неповторяющееся чтение



![](../../_png/Pasted%20image%2020260216200828.png)

###### Чтение "фантомов"

![](../../_png/Pasted%20image%2020260216200911.png)

##### Уровни изоляции

- Read uncommited
- Read commited
- Repeatable read
- Serializable

###### 2PL



![](../../_png/Pasted%20image%2020260216202120.png)

###### MVCC

- t_xmin
- t_xmax

![](../../_png/Pasted%20image%2020260216201957.png)

##### Устойчивость

Гарантирует, что после фиксации транзакции в базе, она постоянно сохраняется с помощью резервных копий и журналов транзакций. В случае сбоя эти механизмы могут использоваться для восстановления зафиксированных транзакций. 

###### Wal


##### Base
















### Объекты баз данных
### Брокеры сообщений
### Альтернативные способы хранения данных

#### Хранение на клиенте

![](../../_png/Pasted%20image%2020260217203128.png)

#### CDN

- Исходный (origin), на котором размещён запрашиваемый сайт, а также связанный с ним визуальный-, музыкальный-, видео-контент 
- PoP (point of presence) - точка присутствия вспомогательных серверов. Их сеть размещается в различных регионах. 
- Proxy-сервер - это промежуточное звено между сервером и конечным пользователем. Он отвечает за перенаправление, оптимизацию и преобразование передаваемого трафика

![](../../_png/Pasted%20image%2020260217203144.png)









## Распределённое хранение данных

### Репликация

Репликация - создание клона базы данных для быстрого подхвата функций повреждённой системы.

Бэкап - это резервное копирование содержимого диска с целью последующего восстановления. 

#### Надёжность

#### Масштабирование чтения

#### Виды ролей в репликации

##### Master - slave

##### Failover

##### Hot satnby

##### Split brain

##### Master - master

##### Конфликты

##### Master - less

#### Типы репликации

##### Strong Consistency
##### Синхронная

##### Eventual Consistency

##### Асинхронная

##### Replication Lag

##### Чтение собственных записей

##### Монотонное чтение

##### Согласованное префиксное чтение

##### Полусинхронная (semisync)

##### Lose-less Semisync

#### Форматы передачи данных





### CAP теорема
### Партиционирование
### Шардирование
### Дополнительное











## Паттерны и приёмы проектирования

### Паттерны проектирования

Хорошая база содержится в книге "Проектирование высоконагруженных приложений"

![](../../_png/Pasted%20image%2020260217194736.png)

#### Rolling Release



![](../../_png/Pasted%20image%2020260217194845.png)

#### Blue/green release



![](../../_png/Pasted%20image%2020260217194930.png)

#### Canary Release



![](../../_png/Pasted%20image%2020260217194951.png)

MVP

Трёхзвенная архитектура

Толстый клиент

Pub / sub

Heart bit

Service Discovery

CQRS

Retries

Идемпотентность

Backoff

Backpressure

Circuit breaker

Graceful Degradation

Fallback

Версионирование кэша


Тегирование кэша


Отложенное выполнение задач

Polling

Long polling

Streaming


Map Reduce

#### Микросервисная архитектура

##### Агрегатор





##### Цепочка




#### Событийно-ориентированная архитектура

Event Notification

State Transfer

Event Collaboration

#### Throttling / debouncing



![](../../_png/Pasted%20image%2020260217201659.png)



![](../../_png/Pasted%20image%2020260217201710.png)



![](../../_png/Pasted%20image%2020260217201721.png)



![](../../_png/Pasted%20image%2020260217201734.png)



![](../../_png/Pasted%20image%2020260217201744.png)



### Консенсус

Консенсус представляет собой согласование определённых действий между несколькими узлами. 



#### Распределённые транзакции



![](../../_png/Pasted%20image%2020260217200518.png)


#### Двухфазная транзакция (2PC)


![](../../_png/Pasted%20image%2020260217200533.png)


![](../../_png/Pasted%20image%2020260217200542.png)


![](../../_png/Pasted%20image%2020260217200550.png)


![](../../_png/Pasted%20image%2020260217200559.png)






#### Saga



![](../../_png/Pasted%20image%2020260217200502.png)



![](../../_png/Pasted%20image%2020260217200445.png)



#### Transaction outbox



![](../../_png/Pasted%20image%2020260217200413.png)

#### Распределённые блокировки



![](../../_png/Pasted%20image%2020260217200346.png)



![](../../_png/Pasted%20image%2020260217200357.png)


#### Выбор лидера



![](../../_png/Pasted%20image%2020260217200314.png)



![](../../_png/Pasted%20image%2020260217200329.png)





#### Алгоритм забияки


![](../../_png/Pasted%20image%2020260217200213.png)


![](../../_png/Pasted%20image%2020260217200221.png)



![](../../_png/Pasted%20image%2020260217200232.png)



![](../../_png/Pasted%20image%2020260217200242.png)



![](../../_png/Pasted%20image%2020260217200250.png)







#### Raft и Paxos




### Установка требований к системе

#### Функциональные требования

Заявление о том, как должна вести себя система. Оно определяет то, что должна делать система, что должна делать система, чтобы удовлетворять потребностям или ожиданиям пользователя. Эти требования можно рассматривать как функции, которые обнаруживает пользователь.

#### Нефункциональные требования

Требования, определяющие свойства, которые система должна демонстрировать, или ограничения, которые она должна соблюдать, не относящиеся к поведению системы. Например, производительность, удобство сопровождения, расширяемость, надёжность.  

### Рассчёт нагрузки на систему




















## Дизайн популярных систем














---

## Основные термины

Масштабируемость (Scalability): вертикальная vs горизонтальная
Доступность (Availability): SLA, SLO, SLI, 9s (99.9%, 99.99%)
Производительность (Performance): latency, throughput, QPS
Надёжность (Reliability): fault tolerance, resilience
Консистентность (Consistency): ACID, CAP theorem, BASE
Пропускная способность (Throughput): TPS, RPS
Задержка (Latency): p50, p95, p99
Кэширование (Caching): cache-aside, write-through, write-back
Балансировка нагрузки (Load Balancing): round-robin, least connections, consistent hashing
Репликация (Replication): master-slave, master-master
Шардирование (Sharding): horizontal partitioning
Очереди (Message Queues): pub/sub, point-to-point
API Gateway: routing, authentication, rate limiting
CDN (Content Delivery Network)
Микросервисы vs Монолит
Stateless vs Stateful сервисы

## Хранение данных

Детализировать типы и подходы:

Типы баз данных:
Реляционные (SQL): PostgreSQL, MySQL, Oracle
NoSQL: документные (MongoDB), ключ-значение (Redis), колоночные (Cassandra), графовые (Neo4j)
In-memory: Redis, Memcached
Поисковые: Elasticsearch, Solr
Индексы: B-tree, LSM-tree, hash indexes
Транзакции: ACID свойства, изоляция уровней
Нормализация vs Денормализация
Оптимизация запросов: explain plans, индексы, партиционирование
Backup и восстановление: стратегии, RPO, RTO


## Распределённое хранение данных

Углубить концепции распределённых систем:

CAP Theorem: Consistency, Availability, Partition tolerance
PACELC Theorem: расширение CAP
Консенсус алгоритмы: Raft, Paxos, PBFT
Репликация:
Синхронная vs асинхронная
Master-slave, master-master, multi-master
Quorum, read/write quorum
Шардирование:
Стратегии: range-based, hash-based, directory-based
Проблемы: hot spots, rebalancing
Consistent hashing
Распределённые транзакции: 2PC, Saga pattern, TCC
Eventual consistency: vector clocks, CRDTs
Distributed locks: Redis, ZooKeeper, etcd
Leader election: алгоритмы и реализации

## Паттерны и приёмы проектирования

Систематизировать архитектурные паттерны:

Архитектурные паттерны:
Layered Architecture
Microservices
Event-Driven Architecture
CQRS (Command Query Responsibility Segregation)
Event Sourcing
Serverless
Service Mesh
Паттерны масштабирования:
Horizontal vs Vertical scaling
Database sharding
Read replicas
Caching strategies
CDN
Паттерны отказоустойчивости:
Circuit Breaker
Retry with exponential backoff
Bulkhead
Timeout
Graceful degradation
Паттерны обработки данных:
Batch processing
Stream processing
MapReduce
Lambda architecture
Kappa architecture
Паттерны коммуникации:
API Gateway
Service Discovery
Message Queue
Pub/Sub
Request/Response
Паттерны безопасности:
Authentication & Authorization
OAuth 2.0, JWT
Rate limiting
Encryption at rest and in transit

## Дизайн популярных систем

Добавить case studies реальных систем:

URL Shortener (bit.ly, TinyURL)
Distributed Cache (Redis, Memcached)
Chat System (WhatsApp, Slack)
News Feed (Facebook, Twitter)
Video Streaming (YouTube, Netflix)
Search Engine (Google)
E-commerce Platform (Amazon)
Ride-sharing (Uber, Lyft)
Payment System (Stripe, PayPal)
File Storage (Dropbox, Google Drive)
Notification System
Analytics System
Для каждой системы описать:

Функциональные требования
Нефункциональные требования (масштаб, производительность)
Архитектура высокого уровня
Компоненты системы
Масштабирование и оптимизация
Trade-offs и решения
Дополнительные разделы для добавления

## Методология проектирования

Процесс интервью по System Design
Шаги проектирования: требования, оценка масштаба, API, схема данных, архитектура, детализация
Оценка масштаба: пользователи, запросы, хранение, пропускная способность
Back-of-the-envelope calculations


## Инструменты и технологии


Базы данных: PostgreSQL, MySQL, MongoDB, Cassandra, Redis, Elasticsearch
Очереди: RabbitMQ, Kafka, AWS SQS
Кэширование: Redis, Memcached, CDN
Мониторинг: Prometheus, Grafana, ELK Stack
Оркестрация: Kubernetes, Docker Swarm
Service Mesh: Istio, Linkerd


## Метрики и мониторинг

Метрики производительности
Логирование и трейсинг
Алертинг
Dashboards


---
## Дополнительно


### Этапы проектирования системы

1. Сбор требований
2. 
3. REST API (взаимодействие систем)



### ДЗ

#### Первая часть

**Необходимо спроектировать мессенджер WhatsApp** самостоятельно (_даже если вы еще ничего не знаете или если ваш дизайн будет состоять из одного сервера и БД - это будет НОРМАЛЬНО_)

**Показывать этот дизайн никому не нужно**, он будет лишь только у вас - после каждого занятия вы будете возвращаться к этому дизайну - смотреть на то, что было сделано неправильно и изменять, исходя из полученных знаний на уроках (_а в конце курса, я покажу - как бы я спроектировал подобную систему_).

**Требования к системе:**

- Сезонности у системы нет;
- Системой будут пользоваться по всему миру;
- Приложение будет показывать непрочитанные сообщения;
- Приложение будет поддерживать чаты и личные сообщения;
- Отправлять можно только текст и картинки в сообщениях;
- Максимальный размер изображения в сообщении = 1МБ;
- Максимальное кол-во изображений в сообщении = 3;
- Максимальный размер текста в сообщении = 2000 символов;
- Клиентами будут мобильные, десктопные и WEB приложения;
- 200 000 000 уникальных пользователей заходят в приложение каждый день;
- Каждый пользователь в среднем отправляет 10 сообщений в день;
- Каждый пользователь в среднем просматривает сообщения 20 раз в день;
- Система должна работать 24 на 7 (допустимо 4 часа и 23 минуты простоя в год);
- Приложение должно показывать статусы онлайн/оффлайн пользователей, а также когда пользователь был последний раз в сети;
- Сообщение до получателя должно успевать доходить за 3 секунды (_если пользователя нет в сети - ему должно прийти Push уведомление на мобильный телефон_);
- Приложение должно поддерживать кросс-девайсную синхронизацию (_если у вас это приложение открыто на телефоне и ноутбуке, и например вы прочитали сообщение на телефоне, то сообщение должно отобразиться прочитанным и на ноутбуке_);

**Дополнительно:**

- Фронтенд проектировать не нужно (_концентрируемся только на бэкенде_)
- Аутентификацию проектировать не нужно (_представим, что эта часть системы уже кем-то реализована_)

Для дизайна можно пользоваться инструментами [Lucidchart](https://www.lucidchart.com/pages/ru) или [Miro](https://miro.com/) - там достаточно богатый функционал и в будущем вам будет просто туда вносить изменения. В дизайне хотелось бы видеть:

- Расчет нагрузки и потребления памяти у основных операций.
- Модель данных (_описать основные сущности в БД и как они взаимосвязаны_);
- API (_расписывать REST или GraphQL не нужно - просто словами опишите основные операции над вашей системой_);
- Верхнеуровневое проектирование основных компонентов системы и их отношений с другими компонентами системы;

**Желаем удачи в дизайне WhatsApp!** (_после курса будет очень любопытно понаблюдать за собственным прогрессом_)

#### Вторая часть

**Итоговый проект**

Все домашние задания вас постепенно приближали к созданию итогового проекта по проектированию социальной сети ВКонтакте.

Хотелось бы, чтобы у вас в итоге получился весомый репозиторий, с полноценной архитектурой приложения, чтобы в будущем вы могли это продемонстрировать на собеседованиях или рассказать об этом своему работодателю.

**Функциональные требования** - их необходимо взять из первого домашнего задания по проектирования API (_все те операции из API необходимо будет воплотить в будущей архитектуре_).

**Нефункциональные требования** - у вас есть бизнес заказчик [со следующей информацией](https://vc.ru/vk/279614-auditoriya-vkontakte-2021-ezhegodnyy-rost-prodolzhaetsya) о DAU и активностях пользователей. Остальные нефункциональные требования по доступности, согласованности, лимитах и всем остальном вам нужно определить самостоятельно, исходя из вашего опыта.

**Верхнеуровневый дизайн** - необходимо сделать верхнеуровневый дизайн с использованием [C4 model](https://c4model.com/) (_не спускаемся ниже второго уровня - только system и container diagram_) и [C4-PlantUML](https://github.com/plantuml-stdlib/C4-PlantUML) (_можно пользоваться_ [_PlantUML Online Editor_](http://www.plantuml.com/plantuml/uml/SyfFKj2rKt3CoKnELR1Io4ZDoSa70000)_, чтобы не приходилось ставить ничего дополнительного на ваш компьютер_)

В репозитории необходимо сделать презентабельную [README.md](http://README.md) с описанием системы и требований, верхнеуровневым дизайном, а также с основыми расчетами. Хотелось бы, чтобы у вас в итоге получилось что-то [похожее на это](https://github.com/Balun-courses/system_design) (_индивидуальность приветствуется_).

### Чеклист

- Availability
- Consistency (strong / eventual)
- Количество пользователей (DAU / MAU)
- Количество сущностей (например кол-во отелей или задач на LeetCode)
- Лимиты и ограничения (например макс размер сообщения / картинки или макс кол-во людей в чате)
- Поведение пользователей (как много операций в день / неделю / месяц осуществляет пользователь)
- Data retention (храним ли все или можем что-то удалять / агрегировать / ...)
- Response time (на создание / получение / удаление / сохранение / ...)
- Безопасность (если нужно)
- Геораспределенность
- Сезонности

### Дополнительные материалы

КНИГИ:

- Высоконагруженные приложения. Программирование, масштабирование, поддержка
- Site Reliability Engineering. Надежность и безотказность как в Google
- System Design. Подготовка к сложному интервью
- Микросервисы. Паттерны разработки и рефакторинга
- Распределенные системы

ВИДЕО-КУРСЫ:

- [HighLoad](https://www.youtube.com/playlist?list=PL4_hYwCyhAvZuoK6Y0FaCh-25jEYtBvDo)
- [Распределенные системы](https://www.youtube.com/playlist?list=PLEqoHzpnmTfAW2gYw2R80EmGDwWqUR9mD)

РЕКОМЕНДУЕМЫЕ СТАТЬИ:

- [Graceful degradation](https://habr.com/ru/companies/yandex/articles/438606/)
- [Теория шардирования](https://habr.com/ru/companies/oleg-bunin/articles/433370/)
- [Consistent против Rendezvous](https://habr.com/ru/companies/mygames/articles/669390/)
- [Как работают реляционные базы данных](https://habr.com/ru/articles/487654/)
- [У семи программистов адрес без дома](https://habr.com/ru/companies/hflabs/articles/260601/)
- [Гид по заголовкам кэширования HTTP для начинающих](https://habr.com/ru/articles/253121/)
- [Как сэкономить миллион долларов на базе данных на высоконагруженном проекте](https://habr.com/ru/companies/oleg-bunin/articles/310690/)
- [Архитектура in-memory СУБД](https://habr.com/ru/companies/vk/articles/562192/)
- [Архитектура Mail.ru Cloud Storage](https://habr.com/ru/companies/vk/articles/513356/)
- [Паттерн Outbox](https://habr.com/ru/companies/lamoda/articles/678932/)
